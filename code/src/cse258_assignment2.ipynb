{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(file):\n",
    "#     total_count = 0\n",
    "    keep = 0\n",
    "    withdraw = 0\n",
    "    for l in gzip.open(file):\n",
    "        l = l.replace(b'true', b'True') # all data read from the file is returned as bytes\n",
    "        l = l.replace(b'false', b'False')\n",
    "        item = eval(l)\n",
    "        year = int(item['reviewTime'].split(',')[1])\n",
    "        if year > 2010 and item['verified'] and 'reviewText' in item.keys():\n",
    "            keep += 1\n",
    "            \n",
    "            yield item\n",
    "        else:\n",
    "            withdraw += 1\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "        print(keep+withdraw, keep, withdraw)\n",
    "        if keep == 140000: break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194963 140000 54963\n"
     ]
    }
   ],
   "source": [
    "dataset = list(parse(\"Electronics_5.json.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overall': 5.0, 'verified': True, 'reviewTime': '10 31, 2016', 'reviewerID': 'A1714OIHN8BLOD', 'asin': 'B00007KDX6', 'style': {'Color:': ' Silver'}, 'reviewerName': 'Angelo S.', 'reviewText': 'Fast ship, No problems..', 'summary': 'Five Stars', 'unixReviewTime': 1477872000}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating count: dict_items([(3.0, 19767), (4.0, 48140), (5.0, 207739), (1.0, 14411), (2.0, 9943)])\n",
      "Average rating: 4.416176666666667\n",
      "Number of reviewer: 197759\n",
      "Number of music: 5723\n",
      "Average review length: 237.69216333333333\n",
      "reviewText: 300000\n",
      "Number of reviews in each year [('2011', 16757), ('2012', 22388), ('2013', 49832), ('2014', 60338), ('2015', 68950), ('2016', 48057), ('2017', 27601), ('2018', 6077)]\n",
      "Average rating of each year: [('2011', 4.2492689622247415), ('2012', 4.320796855458282), ('2013', 4.390471985872532), ('2014', 4.427624382644436), ('2015', 4.468440899202321), ('2016', 4.460474020434068), ('2017', 4.410927140321003), ('2018', 4.405463221984532)]\n"
     ]
    }
   ],
   "source": [
    "rating_count = defaultdict(int)\n",
    "reviewer = defaultdict(int)\n",
    "review_count_year = defaultdict(int) # number of reviews in each year\n",
    "asin = set()\n",
    "ave_review_length = 0\n",
    "ave_rating = 0\n",
    "ave_rating_year = defaultdict(int)\n",
    "count_reviewText = 0\n",
    "\n",
    "# rating count\n",
    "for d in dataset:\n",
    "    rating_count[d['overall']] += 1\n",
    "    ave_rating += d['overall']\n",
    "    if 'reviewText' in d.keys(): # not every item has key 'reviewText'\n",
    "        count_reviewText += 1\n",
    "        ave_review_length += len(d['reviewText']) \n",
    "    reviewer[d['reviewerID']] += 1\n",
    "    asin.add(d['asin'])\n",
    "    \n",
    "    # number of reviews in each year\n",
    "    year = d['reviewTime'].split(',')[1].strip()\n",
    "    review_count_year[year] += 1\n",
    "    \n",
    "    ave_rating_year[year] += d['overall']\n",
    "    \n",
    "# count average year rating \n",
    "for k in ave_rating_year.keys():\n",
    "    ave_rating_year[k] = ave_rating_year[k]/review_count_year[k]\n",
    "    \n",
    "# sort dictionay\n",
    "sorted_reviewer = [(r, c) for r, c in sorted(reviewer.items(), key = lambda i:i[1], reverse = True)]\n",
    "sorted_review_count_year = [(y,n) for y,n in sorted(review_count_year.items(), key = lambda i:int(i[0]))]\n",
    "sorted_ave_rating_year = [(y,r) for y,r in sorted(ave_rating_year.items(), key = lambda i:int(i[0]))]\n",
    "\n",
    "# average rating\n",
    "ave_rating = ave_rating / len(dataset)\n",
    "ave_review_length = ave_review_length / len(dataset)\n",
    "\n",
    "print(\"Rating count:\", rating_count.items())\n",
    "print(\"Average rating:\", ave_rating)\n",
    "print(\"Number of reviewer:\", len(reviewer))\n",
    "print(\"Number of music:\", len(asin))\n",
    "print(\"Average review length:\", ave_review_length)\n",
    "print(\"reviewText:\", count_reviewText)\n",
    "print(\"Number of reviews in each year\", sorted_review_count_year)\n",
    "print(\"Average rating of each year:\", sorted_ave_rating_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive words and negative words\n",
    "\n",
    "positive_words = defaultdict(int)\n",
    "negative_words = defaultdict(int)\n",
    "\n",
    "# review with 'will' and 'if'\n",
    "target_list = []\n",
    "# punctuation = string.punctuation\n",
    "for d in dataset:\n",
    "    in_target = False\n",
    "    words = ''.join([c for c in d['reviewText'] if c not in string.punctuation])\n",
    "    if d['overall'] >= 4: \n",
    "        for w in words.split():\n",
    "            positive_words[w] += 1\n",
    "    else:\n",
    "        for w in words.split():\n",
    "            negative_words[w] += 1\n",
    "            if (w == 'if' or w == 'will' or w == 'when') and not in_target:\n",
    "                target_list.append(d['reviewText'])\n",
    "                in_target = True\n",
    "                \n",
    "\n",
    "positive_words_list = [(w, c/len(positive_words)) for w, c in sorted(positive_words.items(), key = lambda i:i[1], reverse = True)]\n",
    "negative_words_list = [(w, c/len(negative_words)) for w, c in sorted(negative_words.items(), key = lambda i:i[1], reverse = True)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000\n",
      "finish store\n"
     ]
    }
   ],
   "source": [
    "f = open('assignment2_dataset.text', 'w')\n",
    "c = 0\n",
    "for d in dataset:\n",
    "    f.write(str(d) + '\\n')\n",
    "    c+= 1\n",
    "    if c%100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(c)\n",
    "print('finish store')\n",
    "\n",
    "        \n",
    "# train_set = dataset[:100000] \n",
    "# validation_set = dataset[100000:120000] \n",
    "# test_set = dataset[120000:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138330\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "c = 0\n",
    "for l in open('assignment2_dataset.text'):\n",
    "# for l in f.readline():\n",
    "    c +=1\n",
    "    dataset.append(eval(l))\n",
    "    if c%100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(c)\n",
    "clear_output(wait=True)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset[:100000] \n",
    "validation_set = dataset[100000:120000] \n",
    "test_set = dataset[120000:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram and bigram \n",
    "unigram = defaultdict(int)\n",
    "bigram = defaultdict(int)\n",
    "for d in train_set:\n",
    "    words = d['reviewText'].replace('\\n', '').strip()\n",
    "    words = ''.join([c for c in words if c not in string.punctuation])\n",
    "    words = words.split()\n",
    "    for i in range(len(words)):\n",
    "        unigram[words[i]] += 1\n",
    "        \n",
    "    for i in range(len(words)-1):\n",
    "        bigram[words[i] + ' ' + words[i+1]] += 1\n",
    "\n",
    "unigram_list = [w for w in sorted(unigram.items(), key = lambda i:i[1], reverse = True)]\n",
    "bigram_list = [w for w in sorted(bigram.items(), key = lambda i:i[1], reverse = True)]\n",
    "\n",
    "unigram_top_words = [w[0] for w in unigram_list[:1000]]\n",
    "bigram_top_words = [w[0] for w in bigram_list[:1000]]\n",
    "\n",
    "unigram_top_wordsId = dict(zip(unigram_top_words, range(len(unigram_top_words))))\n",
    "bigram_top_wordsId = dict(zip(bigram_top_words, range(len(bigram_top_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'I', 'and', 'to', 'a', 'it', 'for', 'is', 'of', 'my']\n",
      "['of the', 'I have', 'in the', 'on the', 'for the', 'is a', 'and the', 'to the', 'with the', 'for a']\n"
     ]
    }
   ],
   "source": [
    "print(unigram_top_words[:10])\n",
    "print(bigram_top_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf\n",
    "unigram_idf = [math.log(100000/x[1], 10) for x in unigram_list[:1000]]\n",
    "bigram_idf = [math.log(100000/x[1], 10) for x in bigram_list[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing progress: 1820 /100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d5f66a2a35ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigram_top_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviewText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data preprocessing #unigram #bigram\n",
    "\n",
    "X_train_uni, y_train = [], []\n",
    "X_train_bi = []\n",
    "\n",
    "c = 0\n",
    "for d in train_set:\n",
    "    c += 1\n",
    "    #unigram\n",
    "    feat = []\n",
    "    for w in unigram_top_words:\n",
    "        feat.append(d['reviewText'].count(w))\n",
    "    feat.append(1)\n",
    "    X_train_uni.append(feat)\n",
    "    y_train.append(d['overall'])\n",
    "    \n",
    "    #bigram\n",
    "    feat = []\n",
    "    for w in bigram_top_words:\n",
    "        line = d['reviewText'].replace('\\n', '')\n",
    "        for p in string.punctuation:\n",
    "            line = line.replace(p, '')\n",
    "        feat.append(line.count(w))\n",
    "    feat.append(1)\n",
    "    X_train_bi.append(feat)\n",
    "    \n",
    "    if c % 10 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Processing progress:\", c ,\"/100000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing progress: 100000 /100000\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "X_train_uni_tfidf, X_train_bi_tfidf = [], []\n",
    "c = 0\n",
    "for d in train_set:\n",
    "    c += 1\n",
    "    feat = []\n",
    "    for i in range(len(unigram_top_words)):\n",
    "        tfidf = d['reviewText'].count(unigram_top_words[i]) * unigram_idf[i]\n",
    "        feat.append(tfidf)\n",
    "    feat.append(1)\n",
    "    X_train_uni_tfidf.append(feat)\n",
    "    \n",
    "    #bigram\n",
    "    feat = []\n",
    "    for i in range(len(bigram_top_words)):\n",
    "        line = d['reviewText'].replace('\\n', '')\n",
    "        for p in string.punctuation:\n",
    "            line = line.replace(p, '')\n",
    "        tfidf = line.count(bigram_top_words[i]) * bigram_idf[i]\n",
    "        feat.append(tfidf)\n",
    "    feat.append(1)\n",
    "    X_train_bi_tfidf.append(feat)\n",
    "    \n",
    "    if c % 10 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Processing progress:\", c ,\"/100000\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for d in train_set:\n",
    "    y_train.append(d['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "X_train_uni = sklearn.preprocessing.normalize(X_train_uni)\n",
    "X_train_bi = sklearn.preprocessing.normalize(X_train_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "def accuracy(y_pred, y):\n",
    "    return sum([True for i in range(len(y)) if y_pred[i] == y[i]])/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n"
     ]
    }
   ],
   "source": [
    "#KNN #unigram\n",
    "knn_uni = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_uni.fit(X_train_uni, y_train)\n",
    "\n",
    "y_pred = knn_uni.predict(X_train_uni[14000:15000])\n",
    "print(accuracy(y_pred,y_train[14000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n",
      "0.74\n"
     ]
    }
   ],
   "source": [
    "#KNN #bigram\n",
    "knn_bi = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_bi.fit(X_train_bi, y_train)\n",
    "\n",
    "y_pred = knn_bi.predict(X_train_bi[14000:15000])\n",
    "print(accuracy(y_pred,y_train[14000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN #unigram #tfidf\n",
    "knn_uni_tfidf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_uni_tfidf.fit(X_train_uni_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_uni_tfidf.predict(X_train_uni_tfidf[14000:15000])\n",
    "print(accuracy(y_pred,y_train[14000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN #bigram #tfidf\n",
    "knn_bi_tfidf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_bi_tfidf.fit(X_train_bi_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_bi_tfidf.predict(X_train_bi_tfidf[14000:15000])\n",
    "print(accuracy(y_pred,y_train[14000:15000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l1lu/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regress #unigram\n",
    "clf_uni = LogisticRegression(C=100, solver = 'saga')\n",
    "clf_uni.fit(X_train_uni, y_train)\n",
    "y_pred = clf_uni.predict(X_train_uni[14000:15000])\n",
    "print(accuracy(y_pred,y_train[14000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l1lu/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regress #bigram\n",
    "clf_bi = LogisticRegression(C=10, class_weight='balanced')\n",
    "clf_bi.fit(X_train_bi, y_train)\n",
    "y_pred = clf_bi.predict(X_train_bi[14000:15000])\n",
    "print(accuracy(y_pred,y_train[14000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regress #tfidf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM #unigram\n",
    "lin_clf_uni = svm.LinearSVC(C=10)\n",
    "lin_clf_uni.fit(X_train_uni, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_clf_uni.predict(X_train_uni[14000:15000])\n",
    "print(accuracy(y_pred, y_train[14000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM #bigram\n",
    "lin_clf_bi = svm.LinearSVC()\n",
    "lin_clf_bi.fit(X_train_bi, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "y_pred = lin_clf_bi.predict(X_train_bi[14000:15000])\n",
    "print(accuracy(y_pred, y_train[14000:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
